{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f79cd6d",
   "metadata": {},
   "source": [
    "# NumPy Exercise: Chunked Matrix Computation under Memory Constraints\n",
    "\n",
    "## Problem Overview\n",
    "\n",
    "Given two matrices:\n",
    "\n",
    "- `A`: shape `(M, K)`\n",
    "- `B`: shape `(K, N)`\n",
    "\n",
    "You want to compute:\n",
    "\n",
    "C = A @ B\n",
    "\n",
    "However, you must assume that **A and/or B are too large to be processed in a single operation**, and that only a limited amount of memory is available at any time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583b19a4",
   "metadata": {},
   "source": [
    "## Part 1: Chunked Matrix Multiplication\n",
    "\n",
    "### Task\n",
    "\n",
    "Implement a function that computes the matrix product `C = A @ B` by **splitting the computation into chunks**, such that:\n",
    "\n",
    "- No intermediate array larger than `(chunk_size, K)` or `(K, chunk_size)` is created.\n",
    "- The final result must be numerically equivalent to `A @ B` (up to floating point precision).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Constraints\n",
    "\n",
    "1. You **must not** compute `A @ B` directly.\n",
    "2. You **must not** create large intermediate matrices that scale with `(M, N)`.\n",
    "3. You may assume:\n",
    "   - `A` and `B` are dense NumPy arrays\n",
    "   - `chunk_size > 0`\n",
    "4. Raise a clear `ValueError` if shapes are incompatible.\n",
    "\n",
    "---\n",
    "\n",
    "### Hint (optional)\n",
    "\n",
    "Think about computing the output **row-by-row or block-by-block**, accumulating partial results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cea1f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def chunked_matmul(A: np.ndarray,\n",
    "                   B: np.ndarray,\n",
    "                   chunk_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute C = A @ B using chunked computation.\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "M, K, N = 128, 256, 64\n",
    "chunk_size = 32\n",
    "\n",
    "A = np.random.randn(M, K).astype(np.float32)\n",
    "B = np.random.randn(K, N).astype(np.float32)\n",
    "\n",
    "C = chunked_matmul(A, B, chunk_size)\n",
    "C_ref = A @ B\n",
    "\n",
    "print(np.max(np.abs(C - C_ref)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c670286",
   "metadata": {},
   "source": [
    "## Part 2: Chunked Reduction over the Inner Dimension (Advanced)\n",
    "\n",
    "In some systems, even storing a full `(chunk_size, K)` block is not feasible.\n",
    "\n",
    "### Task\n",
    "\n",
    "Implement a version of `chunked_matmul` that **also chunks over the inner dimension `K`**, such that:\n",
    "\n",
    "- At any time, you only hold blocks of size at most:\n",
    "  - `(chunk_M, chunk_K)` from `A`\n",
    "  - `(chunk_K, chunk_N)` from `B`\n",
    "\n",
    "You may choose how to split the dimensions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunked_matmul_3d(A: np.ndarray,\n",
    "                      B: np.ndarray,\n",
    "                      chunk_m: int,\n",
    "                      chunk_n: int,\n",
    "                      chunk_k: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute C = A @ B using chunked computation over M, N, and K.\n",
    "\n",
    "    Constraints:\n",
    "    - A has shape (M, K)\n",
    "    - B has shape (K, N)\n",
    "    - No intermediate array larger than:\n",
    "        (chunk_m, chunk_k) from A\n",
    "        (chunk_k, chunk_n) from B\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "M, K, N = 96, 128, 80\n",
    "chunk_m, chunk_n, chunk_k = 24, 20, 32\n",
    "\n",
    "A = np.random.randn(M, K).astype(np.float32)\n",
    "B = np.random.randn(K, N).astype(np.float32)\n",
    "\n",
    "C = chunked_matmul_3d(A, B, chunk_m, chunk_n, chunk_k)\n",
    "C_ref = A @ B\n",
    "\n",
    "print(\"max error:\", np.max(np.abs(C - C_ref)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c280e3",
   "metadata": {},
   "source": [
    "### Discussion Questions (No Code Required)\n",
    "\n",
    "- What is the computational complexity of your implementation?\n",
    "- How does chunk size affect:\n",
    "  - cache locality?\n",
    "  - numerical error accumulation?\n",
    "  - runtime?\n",
    "- When would chunking over `K` be preferable to chunking over `M`?\n",
    "\n",
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "- This problem simulates real-world constraints such as limited GPU memory or cache-aware computation.\n",
    "- The goal is correctness **and** clarity, not peak performance.\n",
    "- You are not expected to implement parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9459fbaf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
